---
created_at: "2026-01-01T21:24:09+0100"
path: "responses/report_20260101_write-full-report_ai_generated_parallel_items.md"
os: "Linux 6.6.87.2-microsoft-standard-WSL2"
r_version: "R version 4.5.2 (2025-10-31)"
agent: "Codex"
nlss_version: "1.0.0"
---

# AI-Generated Parallel Items and Parallel-Form Quality: A Psychometric Evaluation

`<user-placeholder>`  
`<affiliation-placeholder>`  
`<email-placeholder>`

January 1, 2026

## Abstract

This study evaluated whether individually generated AI parallel items (Form C) for the STARC-5 Emotional Resilience scale achieve psychometric quality comparable to the original form (A) and a human parallel form (B). Participants (N = 53) completed all three forms plus the PSQ-20. Form C demonstrated strong internal consistency and high correlations with Forms A and B, but mean equivalence testing supported equivalence only for A vs. B. Criterion validity with PSQ-20 was negative and of at least moderate magnitude across all forms. Findings indicate that AI-generated parallel forms can be reliable and valid but may diverge in mean level, warranting refinement before being used interchangeably with established forms.

*Keywords:* parallel forms, AI-generated items, reliability, criterion validity, equivalence testing

# AI-Generated Parallel Items and Parallel-Form Quality: A Psychometric Evaluation

## Introduction

Parallel-form assessment evaluates whether alternate versions of a scale measure the same construct with comparable reliability and validity, supporting interchangeability in applied settings (Salkind, 2007). Beyond high correlations, mean-level equivalence is often required when forms are used interchangeably, and equivalence testing is recommended for this purpose (Lakens, 2017; Schuirmann, 1987). The present study examines whether AI-generated parallel items (Form C) for the STARC-5 Emotional Resilience scale perform comparably to the original form (A) and a human-generated parallel form (B). Criterion validity was evaluated using the 20-item Perceived Stress Questionnaire (PSQ-20), a validated measure of perceived stress (Fliege et al., 2005; Levenstein et al., 1993).

## Method

### Participants

All respondents who completed the study were retained (N = 53). The sample was predominantly female (67.9%), with 30.2% male and 1.9% diverse. Education ranged from no formal degree to doctoral level, with the largest groups reporting mid-level secondary education (35.9%) or a bachelor/master-level degree (41.5% combined). Employment status was primarily full-time (43.4%). Age was reported categorically (19 to >67); the most frequent categories were 20 years (15.1%) and 55 years (9.4%). All participants indicated serious participation (ernsthaftigkeit = 1).

### Measures

**STARC-5 Emotional Resilience.** The STARC-5 was administered in three forms: original (A), human parallel (B), and AI-generated parallel (C). Each form contained 7 items on a 1–5 Likert scale. Form C items were generated individually for each participant based on the A-form content. Scale scores were computed as item means.

**PSQ-20.** The PSQ-20 is a 20-item measure of perceived stress with established psychometric properties (Fliege et al., 2005). Reverse-keyed items were recomputed (items 1, 4, 6, 8, 12, 14, 16, 19), and the PSQ-20 total was computed as the mean of all 20 items.

### Procedure

Participants completed the study online. The order of the three resilience forms was randomized across six sequences (ABC, ACB, BAC, BCA, CAB, CBA). Demographics were collected after the scales.

### Analytic Strategy

Scale reliability was evaluated with Cronbach’s α and McDonald’s ω. Parallel-form reliability was assessed with Pearson correlations and absolute-agreement ICCs (ICC(2,1)) between form total scores. Criterion validity was evaluated via Pearson correlations between each form and PSQ-20. Mean equivalence was tested using paired-samples TOST with equivalence bounds set at ±0.25 pooled SD for each pair. Alpha was set to .05 (two-tailed), with no multiplicity correction. Normality of paired differences was evaluated using Shapiro–Wilk tests.

## Results

### Descriptive Statistics

**Table 1**

*Sample characteristics*

| Characteristic | Category | n | % |
| --- | --- | --- | --- |
| Gender | Female (0) | 36 | 67.9 |
|  | Male (1) | 16 | 30.2 |
|  | Diverse (2) | 1 | 1.9 |
| Education | Mittlere Reife (3) | 19 | 35.9 |
|  | (Fach-) Abitur (4) | 6 | 11.3 |
|  | Ausbildung (5) | 6 | 11.3 |
|  | Bachelor (6) | 16 | 30.2 |
|  | Master/PhD (7) | 4 | 7.5 |
| Employment | Not employed (0) | 13 | 24.5 |
|  | Part-time (1) | 7 | 13.2 |
|  | Full-time (2) | 23 | 43.4 |
|  | Self-employed (3) | 10 | 18.9 |
| Order | ACB | 15 | 28.3 |
|  | BCA | 9 | 17.0 |
|  | BAC | 8 | 15.1 |
|  | CAB | 8 | 15.1 |
|  | CBA | 7 | 13.2 |
|  | ABC | 6 | 11.3 |

*Note.* Age was collected in categorical bins (19 to >67); the most frequent categories were age 20 (15.1%) and 55 (9.4%). Percentages are valid %.

**Table 2**

*Descriptive statistics and reliability (recomputed means)*

| Scale | M | SD | α | ω |
| --- | --- | --- | --- | --- |
| STARC-5 A | 3.49 | 0.69 | .81 | .83 |
| STARC-5 B | 3.57 | 0.61 | .79 | .82 |
| STARC-5 C | 3.34 | 0.67 | .85 | .86 |
| PSQ-20 | 2.36 | 0.52 | .92 | .92 |

*Note.* Scale scores are item means. PSQ-20 reverse items were recomputed prior to scoring.

### Preliminary Analyses

Normality checks for paired differences indicated no significant departures for A vs. B (p = .240) or A vs. C (p = .090), but the B vs. C difference showed non-normality (p = .001). Given the sample size and robustness of paired tests, TOST results were interpreted with this caveat for B vs. C.

### Hypothesis Testing

**H1: Parallel-form reliability.** Pearson correlations between form totals were high (A–B r = .887, A–C r = .824, B–C r = .881; all p < .001). Absolute-agreement ICCs were also high and exceeded .80 for all form pairs (ICC(2,1) = .876 for A–B; .806 for A–C; .827 for B–C), supporting acceptable-to-high parallel-form reliability.

**H2: Internal consistency.** All forms showed acceptable-to-high internal consistency (α range .79–.85; ω range .82–.86). Form C’s reliability was comparable to or higher than A and B.

**H3: Criterion validity.** Correlations with PSQ-20 were negative and of at least moderate magnitude: A–PSQ r = −.341 (p = .012), B–PSQ r = −.392 (p = .004), C–PSQ r = −.526 (p < .001). These findings support criterion validity for all three forms.

**H4: Mean equivalence.** TOST results supported equivalence for A vs. B only. A vs. C and B vs. C failed to meet equivalence within ±0.25 pooled SD.

**Table 3**

*Parallel-form reliability and criterion validity correlations*

| Comparison | r (95% CI) | p | ICC(2,1) (95% CI) |
| --- | --- | --- | --- |
| A vs B | .887 [.811, .934] | < .001 | .876 [.795, .926] |
| A vs C | .824 [.712, .895] | < .001 | .806 [.688, .882] |
| B vs C | .881 [.801, .930] | < .001 | .827 [.723, .895] |
| A vs PSQ-20 | −.341 [−.560, −.078] | .012 | — |
| B vs PSQ-20 | −.392 [−.599, −.136] | .004 | — |
| C vs PSQ-20 | −.526 [−.697, −.298] | < .001 | — |

**Table 4**

*Equivalence testing (paired TOST; ±0.25 pooled SD)*

| Pair | Mean Diff | Δ (±0.25 SD) | 90% CI | TOST p | Equivalent |
| --- | --- | --- | --- | --- | --- |
| A vs B | −0.073 | 0.163 | [−0.146, 0.001] | .023 | Yes |
| A vs C | 0.154 | 0.171 | [0.060, 0.247] | .380 | No |
| B vs C | 0.226 | 0.160 | [0.153, 0.300] | .932 | No |

*Note.* Δ is the equivalence margin defined as ±0.25 × pooled SD for each pair.

## Discussion

### Summary of Findings

AI-generated Form C achieved strong internal consistency and high correlations with Forms A and B, supporting parallel-form reliability and criterion validity. However, mean-level equivalence was supported only between Forms A and B, indicating that Form C scores differed enough in level to fail equivalence at the prespecified margin.

### Limitations

The sample size was modest and the B–C difference showed non-normality. Additionally, the equivalence margin was fixed at ±0.25 pooled SD; alternative margins could affect conclusions.

### Implications

These results suggest that AI-generated parallel items can reach acceptable reliability and criterion validity but may require calibration to ensure mean-level interchangeability. This has practical implications for using individualized AI-generated forms in assessment settings.

### Future Directions

Future work should test larger samples, refine item-generation constraints, and explore methods to align mean levels across forms while preserving reliability and validity.

## Conclusion

Form C demonstrates psychometric promise, matching the original and human parallel forms in reliability and criterion validity but not in mean-level equivalence. AI-generated parallel forms may be viable with additional calibration and validation.

## References

Fliege, H., Rose, M., Arck, P., Walter, O. B., Kocalevent, R.-D., Weber, C., & Klapp, B. F. (2005). The Perceived Stress Questionnaire (PSQ) reconsidered: Validation and reference values from different clinical and healthy adult samples. *Psychosomatic Medicine, 67*(1), 78–88. https://doi.org/10.1097/01.psy.0000151491.80178.78

Lakens, D. (2017). Equivalence tests: A practical primer for t tests, correlations, and meta-analyses. *Social Psychological and Personality Science, 8*(4), 355–362. https://doi.org/10.1177/1948550617697177

Levenstein, S., Prantera, C., Varvo, V., Scribano, M. L., Berto, E., Luzi, C., & Andreoli, A. (1993). Development of the Perceived Stress Questionnaire: A new tool for psychosomatic research. *Journal of Psychosomatic Research, 37*(1), 19–32.

Salkind, N. J. (Ed.). (2007). Parallel forms reliability. In *Encyclopedia of Measurement and Statistics*. Sage Publications.

Schuirmann, D. J. (1987). A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability. *Journal of Pharmacokinetics and Biopharmaceutics, 15*(6), 657–680.

---

Created with NLSS.
